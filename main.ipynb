{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ea6ed37a-7058-485a-84f3-3acc12e48809",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<div style=\"background-image: url('https://cdn-images-1.medium.com/max/1200/1*OOWSoWHeQ5kyJ4N0P2ptNA.png');padding-top: 40px\">\n",
    "<p style=\"text-align: center;\">\n",
    "  <a href=\"https://itb.ac.id/\" style=\"margin-top:20px;\">\n",
    "    <img src=\"https://seeklogo.com/images/I/institut-teknologi-bandung-logo-7B8F816823-seeklogo.com.png\" alt=\"Logo\" width=100 height=100>\n",
    "  </a>\n",
    "  <div style=\"text-align: center;font-weight:bold; margin:5px; font-size:30px;font-family: fantasy;\">IF3270 Machine Learning</div>\n",
    "  <p style=\"text-align: center;margin:0px;font-family: fantasy;font-size:20px\">\n",
    "    Implementasi Algoritma FFNN\n",
    "    <br style=\"text-align: center;\">\n",
    "    <br style=\"text-align: center;\">\n",
    "  </p>\n",
    "  <p style=\"text-align: center; margin:0px; margin-top:50px; font-weight: bold; font-size: 30px; font-family: fantasy;\">Anggota</p>\n",
    "  <div style=\"display:flex; flex-wrap:wrap; text-align:center; flex-direction: row; padding:50px 0;\">\n",
    "    <div style=\"line-height:1px; flex: 25%; margin:auto;\">\n",
    "      <img src=\"https://i.ibb.co/HY222Nj/rexy.jpg\" width=150 height=150 style=\"border-radius:50%; margin:auto;object-fit:cover;\" >\n",
    "      <p style=\"font-family:Courier; font-weight:bold; font-size:20px;text-align:center;\">13519010</p>\n",
    "      <p style=\"font-family:Courier; font-size:20px;text-align:center;\">Rexy</p>\n",
    "    </div>\n",
    "    <div style=\"line-height:1px; flex: 25%; margin:auto;\">\n",
    "      <img src=\"https://i.ibb.co/xGmzX02/louis.jpg\" width=150 height=150 style=\"border-radius:50%; margin:auto;object-fit:cover;\" >\n",
    "      <p style=\"font-family:Courier; font-weight:bold; font-size:20px;text-align:center;\">13519016</p>\n",
    "      <p style=\"font-family:Courier; font-size:20px;text-align:center;\">Louis</p>\n",
    "    </div>\n",
    "    <div style=\"line-height:1px; flex: 25%; margin:auto;\">\n",
    "      <img src=\"https://i.ibb.co/gDxQKbx/dito.jpg\" width=150 height=150 style=\"border-radius:50%; margin:auto;object-fit:cover;\" >\n",
    "      <p style=\"font-family:Courier; font-weight:bold; font-size:20px;text-align:center;\">13519159</p>\n",
    "      <p style=\"font-family:Courier; font-size:20px;text-align:center;\">Benidictus</p>\n",
    "    </div>\n",
    "    <div style=\"line-height:1px; flex: 25%; margin:auto;\">\n",
    "      <img src=\"https://i.ibb.co/NmWB3BH/kevin.jpg\" width=150 height=150 style=\"border-radius:50%; margin:auto;object-fit:cover;\" >\n",
    "      <p style=\"font-family:Courier; font-weight:bold; font-size:20px;text-align:center;\">13519216</p>\n",
    "      <p style=\"font-family:Courier; font-size:20px;text-align:center;\">Kevin</p>\n",
    "    </div>\n",
    "  </div>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00001-11a14650-4011-4e12-a43f-594ec955cde7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3766,
    "execution_start": 1646494188781,
    "source_hash": "7958d4a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/deysiolgasitanggang/opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.20.3)\n",
      "Requirement already satisfied: graphviz in /Users/deysiolgasitanggang/opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (0.19.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00002-d1f0ee71-b156-4f28-ba8d-409762de1dec",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1646494192554,
    "source_hash": "2e353441"
   },
   "outputs": [],
   "source": [
    "# import library\n",
    "import json\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00003-c236dd4a-f7df-46c5-a0d8-9860dbed80a7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1646494192567,
    "source_hash": "9777ddd0"
   },
   "outputs": [],
   "source": [
    "# read model file from filesystem\n",
    "f = open(\"model2-sigmoid.json\", \"r\")\n",
    "\n",
    "# loads model and parse to json object\n",
    "model = json.loads(f.read())\n",
    "\n",
    "network_depth = model[\"Network_Depth\"]\n",
    "learning_rate = model[\"Learning_Rate\"]\n",
    "num_of_input = model[\"Num_Of_Input\"]\n",
    "layer_group = model[\"Layers\"]\n",
    "weight_group = model[\"Weights\"]\n",
    "input_group = model[\"Input\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00004-5ea37283-29c0-4e2b-9ace-f82badd34e10",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1646494192587,
    "source_hash": "4c7f99e4"
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, width, activation=None):\n",
    "        '''\n",
    "        [Attributes]\n",
    "            _width      : int       { banyak node pada layer }\n",
    "            _activation : func      { fungsi aktivasi layer, None jika layer input }\n",
    "            nodes       : list[float] / list[int] { nilai setiap node pada layer }\n",
    "        '''\n",
    "        self._width = width\n",
    "        self._type = activation\n",
    "       \n",
    "        # Set the activation function self._activation = None\n",
    "        self._activation = self.linear\n",
    "        if activation is not None:\n",
    "            if activation == \"linear\":\n",
    "                self._activation = self.linear\n",
    "            if activation == \"sigmoid\":\n",
    "                self._activation = self.sigmoid\n",
    "            if activation == \"relu\":\n",
    "                self._activation = self.relu\n",
    "            if activation == \"softmax\":\n",
    "                self._activation = self.softmax\n",
    "            \n",
    "        self.nodes = [0] * self._width\n",
    "    \n",
    "    def set_nodes(self, val=0):\n",
    "        '''\n",
    "        [DESC]\n",
    "            Menginisialisasi nilai setiap node pada layer\n",
    "        [PARAMS]\n",
    "            val     : int/float         { nilai yang akan diinisialisasi untuk setiap node pada layer }\n",
    "            val     : list[int]|list[float]\n",
    "        '''\n",
    "        if isinstance(val, (int, float)):\n",
    "            self.nodes = [val] * self._width\n",
    "        if isinstance(val, list):\n",
    "            self.nodes = val\n",
    "    \n",
    "    '''Activation Functions'''\n",
    "    def activate(self):\n",
    "        '''\n",
    "        [DESC]\n",
    "            Abstraksi yang dipanggil di NeuralNetwork untuk melakukan\n",
    "            fungsi aktivasi pada setiap node di layer ini\n",
    "        '''\n",
    "        self._activation()\n",
    "\n",
    "    def sigmoid(self):\n",
    "        '''\n",
    "        [DESC]\n",
    "            Mengubah attr nodes dari perkalian vektor weight dengan node\n",
    "            menjadi list dengan rentang nilai 0 - 1\n",
    "        [PARAMS]\n",
    "            \n",
    "        '''\n",
    "        for i, z in enumerate(self.nodes):\n",
    "            self.nodes[i] = 1 / (1 + math.exp(-z))\n",
    "    \n",
    "    def linear(self):\n",
    "        '''\n",
    "        [DESC]\n",
    "            Mengubah attr nodes dari perkalian vektor weight dengan node\n",
    "        [PARAMS]\n",
    "            X   : list[float]     { input node }\n",
    "            W   : list[float]     { weight setiap node }\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def relu(self):\n",
    "        '''\n",
    "        [DESC]\n",
    "            Menghitung hasil fungsi aktivasi relu.\n",
    "            Jika nilai dibawah 0 maka kembalian adalah 0, Jika tidak maka mengembalikan nilai dari fungsi linear.\n",
    "        [PARAMS]\n",
    "            X   : nilai dari masukan dalam bentuk array of array (Matrix)\n",
    "            W   : weight dalam bentuk array of array (Matrix)\n",
    "        '''\n",
    "        for i, z in enumerate(self.nodes):\n",
    "            self.nodes[i] = max(0, z)\n",
    "    \n",
    "    def softmax(self):\n",
    "        '''\n",
    "        [DESC]\n",
    "            Mengubah attr nodes dengan nilai perbandingan seluruh node\n",
    "        '''\n",
    "        temp_z_exps = [np.exp(zi) for zi in self.nodes] # calculate exp(z) for all node in layer\n",
    "        self.sum_exp_z = np.sum(temp_z_exps)\n",
    "        for i, z in enumerate(temp_z_exps):\n",
    "            self.nodes[i] = z / self.sum_exp_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00005-1628cb3a-f49a-4749-a65b-697ce9e44e2d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 42,
    "execution_start": 1646494192626,
    "source_hash": "fecd0e44"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, data):\n",
    "        '''\n",
    "        [ATTRIBUTES]\n",
    "            n_\n",
    "        Nilai data diisi dari model\n",
    "        '''\n",
    "        self.depth = data[\"Network_Depth\"]\n",
    "        self.n_input = data[\"Num_Of_Input\"]\n",
    "        \n",
    "        self._layers = []\n",
    "        for i, layer in enumerate(data[\"Layers\"]):\n",
    "            assert i == layer[\"depth\"]  # check that the json file did not miss a layer\n",
    "            n_node = layer[\"width\"]\n",
    "            activation = layer[\"activation\"]\n",
    "            temp_layer = Layer(width=n_node, activation=activation)\n",
    "            self._layers.append(temp_layer)\n",
    "        \n",
    "        self._weights = [0] * len(data[\"Weights\"])\n",
    "        for i, weight in enumerate(data[\"Weights\"]):\n",
    "            assert i == weight[\"depth_origin\"]\n",
    "            self._weights[i] = weight[\"values\"]\n",
    "            \n",
    "\n",
    "    def init_input_layer(self, input_instance):\n",
    "        '''\n",
    "        [DESC]\n",
    "            Menginisialisasi input layer dengan instance dari dataset\n",
    "        [PARAMS]\n",
    "            input_instance      : list[int|float]   { sebuah input dari dataset }\n",
    "        '''\n",
    "        self._layers[0].nodes = input_instance\n",
    "    \n",
    "    def feed_forward(self, input_group, n_batch=None):\n",
    "        if n_batch is None:\n",
    "            n_batch = len(input_group)\n",
    "        n_data = len(input_group)\n",
    "        \n",
    "        for i in range(math.ceil(n_data/n_batch)):\n",
    "            print(f\"{'#'*30}\\nBatch {i+1}:\")\n",
    "            start_idx_data = i * n_batch\n",
    "            end_idx_data = (i+1) * n_batch\n",
    "            self.feed_forward_batch(input_group[start_idx_data:end_idx_data])\n",
    "            \n",
    "            # Back-propagation here\n",
    "    \n",
    "    def feed_forward_batch(self, input_group):\n",
    "        '''\n",
    "        [DESC]\n",
    "            Melakukan proses feed forward untuk 1 batch sekaligus\n",
    "        [PARAMS]\n",
    "            input       : input dari file hmm atau dalam bentuk list atau Layer(?)\n",
    "        [RETURN]\n",
    "            output      : Layer     { layer output } \\t(1)\n",
    "            output      : list[int|float]     { list }     (2)\n",
    "            # belum diputuskan yg mana 1/2\n",
    "        '''\n",
    "        hasil = [0] * self.n_input\n",
    "        for i, masukan in enumerate(input_group):\n",
    "            masukan_temp = [1] + masukan\n",
    "            self.init_input_layer(masukan)\n",
    "            print('Input Layer : [x1, x2] =', self._layers[0].nodes)\n",
    "            for j in range(1, network_depth):\n",
    "                layer = self._layers[j]\n",
    "                w = np.array(self._weights[j-1])    # matrix of weights\n",
    "                x = np.array(masukan_temp)          # array of input from lower layer\n",
    "                sigma = np.matmul(w,x)              # matrix multiplication\n",
    "                layer.nodes = sigma.tolist()        # assignment from result multiplication into array nodes\n",
    "                text = 'Hidden Layer = [h1, h2] :' if (j < network_depth - 1) else 'Output Layer = y :'\n",
    "                layer.activate()\n",
    "                print(text, layer.nodes)\n",
    "                    \n",
    "                '''hasil aktivasi dijadikan sebagai input pada layer di atasnya\n",
    "                perlu ditambahkan '1' sebagai bias untuk hidden layer'''\n",
    "                if(j == network_depth-1):\n",
    "                    masukan_temp = layer.nodes\n",
    "                    break\n",
    "                else:\n",
    "                    masukan_temp = [1] + layer.nodes\n",
    "                \n",
    "            hasil[i] = masukan_temp\n",
    "            print(f'Hasil data {i+1}: {masukan} -> {[round(e) for e in hasil[i]]} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00006-0f0901fa-c77f-453f-9bca-536f2c7cddae",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1646494192669,
    "source_hash": "2bb2236d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Batch 1:\n",
      "Input Layer : [x1, x2] = [0, 0]\n",
      "Hidden Layer = [h1, h2] : [4.5397868702434395e-05, 0.9999999999999065]\n",
      "Output Layer = y : [4.543910487654591e-05]\n",
      "Hasil data 1: [0, 0] -> [0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "neural_network = NeuralNetwork(model)\n",
    "neural_network.feed_forward(input_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-b5991f8a-d51a-4cbb-9024-a79eeb751f0c",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00008-ed5e3f0d-918e-4d56-a17d-a16e8ebf477e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 35,
    "execution_start": 1646494192670,
    "source_hash": "22735b52"
   },
   "outputs": [],
   "source": [
    "from graphviz import Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00009-96b43493-62f1-4a72-8ec6-df2b8b781a1f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 127,
    "execution_start": 1646494192706,
    "source_hash": "2f29a103"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/deysiolgasitanggang/Library/Mobile Documents/com~apple~CloudDocs/Kuliah/Semester 6/Machine Learning/Tubes 1 ML/main.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/deysiolgasitanggang/Library/Mobile%20Documents/com~apple~CloudDocs/Kuliah/Semester%206/Machine%20Learning/Tubes%201%20ML/main.ipynb#ch0000009?line=165'>166</a>\u001b[0m     dot\u001b[39m.\u001b[39mrender(\u001b[39m'\u001b[39m\u001b[39mneural_network_01\u001b[39m\u001b[39m'\u001b[39m, view\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/deysiolgasitanggang/Library/Mobile%20Documents/com~apple~CloudDocs/Kuliah/Semester%206/Machine%20Learning/Tubes%201%20ML/main.ipynb#ch0000009?line=166'>167</a>\u001b[0m     \u001b[39m# 'neural_network_01.png'\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/deysiolgasitanggang/Library/Mobile%20Documents/com~apple~CloudDocs/Kuliah/Semester%206/Machine%20Learning/Tubes%201%20ML/main.ipynb#ch0000009?line=168'>169</a>\u001b[0m result_txt \u001b[39m=\u001b[39m generate_txt(neural_network)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/deysiolgasitanggang/Library/Mobile%20Documents/com~apple~CloudDocs/Kuliah/Semester%206/Machine%20Learning/Tubes%201%20ML/main.ipynb#ch0000009?line=169'>170</a>\u001b[0m \u001b[39m# print(result_txt)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/deysiolgasitanggang/Library/Mobile%20Documents/com~apple~CloudDocs/Kuliah/Semester%206/Machine%20Learning/Tubes%201%20ML/main.ipynb#ch0000009?line=170'>171</a>\u001b[0m build_format(result_txt)\n",
      "\u001b[1;32m/Users/deysiolgasitanggang/Library/Mobile Documents/com~apple~CloudDocs/Kuliah/Semester 6/Machine Learning/Tubes 1 ML/main.ipynb Cell 10'\u001b[0m in \u001b[0;36mgenerate_txt\u001b[0;34m(neural_network)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/deysiolgasitanggang/Library/Mobile%20Documents/com~apple~CloudDocs/Kuliah/Semester%206/Machine%20Learning/Tubes%201%20ML/main.ipynb#ch0000009?line=139'>140</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, prev_node \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(prev_layer_node_names):\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/deysiolgasitanggang/Library/Mobile%20Documents/com~apple~CloudDocs/Kuliah/Semester%206/Machine%20Learning/Tubes%201%20ML/main.ipynb#ch0000009?line=140'>141</a>\u001b[0m     \u001b[39mfor\u001b[39;00m j, next_node \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(next_layer_node_names[\u001b[39m1\u001b[39m:]):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/deysiolgasitanggang/Library/Mobile%20Documents/com~apple~CloudDocs/Kuliah/Semester%206/Machine%20Learning/Tubes%201%20ML/main.ipynb#ch0000009?line=141'>142</a>\u001b[0m         weight \u001b[39m=\u001b[39m weights[j][i]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/deysiolgasitanggang/Library/Mobile%20Documents/com~apple~CloudDocs/Kuliah/Semester%206/Machine%20Learning/Tubes%201%20ML/main.ipynb#ch0000009?line=142'>143</a>\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/deysiolgasitanggang/Library/Mobile%20Documents/com~apple~CloudDocs/Kuliah/Semester%206/Machine%20Learning/Tubes%201%20ML/main.ipynb#ch0000009?line=143'>144</a>\u001b[0m             graph_edges_txt \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mprev_node\u001b[39m}\u001b[39;00m\u001b[39m -> \u001b[39m\u001b[39m{\u001b[39;00mnext_node\u001b[39m}\u001b[39;00m\u001b[39m [xlabel=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mweight\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m, style=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdotted\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, arrowhead=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mopen\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m{\u001b[39;00mNL\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def generate_txt(neural_network: NeuralNetwork):\n",
    "    '''\n",
    "    [DESC]\n",
    "        Buat visualisasi untuk model dalam format graphviz\n",
    "    [PARAMS]\n",
    "        model       : NeuralNetwork     { model yang akan divisualisasikan }\n",
    "    '''\n",
    "    # newline (\\n) variabel, bcos backslashes (\\) aren't allowed inside '''\n",
    "    NL = f\"{chr(10)}\"\n",
    "    layers = neural_network._layers\n",
    "    n_layer = len(layers)\n",
    "    input_layer = layers[0]\n",
    "    hidden_layers = layers[1:-1]\n",
    "    n_hidden_layers = len(hidden_layers)\n",
    "    output_layer = layers[-1]\n",
    "\n",
    "    graph_view_format = '''\n",
    "        graph[ fontname = \"Helvetica-Oblique\",\n",
    "            fontsize = 12,\n",
    "            label = \"\",\n",
    "            size = \"7.75,10.25\"\n",
    "        ];\n",
    "        rankdir = LR;\n",
    "        splines=false;\n",
    "        edge[style=invis];\n",
    "        ranksep= 1.4;'''\n",
    "    \n",
    "    def generate_layer_node_names (sym, n, start=0):\n",
    "        # Generate list of str containing node names in the\n",
    "        # format of [\"sym1\", \"sym2\", \"sym3\", ..., \"symn\"]\n",
    "        return [f\"{sym}{i+start}\" for i in range(n+1)]\n",
    "    input_layer_node_names = generate_layer_node_names(\"x\", input_layer._width)\n",
    "    hidden_layers_node_names = [\n",
    "        generate_layer_node_names(f\"h{depth+1}\", hidden_layers[depth]._width)\n",
    "        for depth in range(n_hidden_layers)\n",
    "    ]\n",
    "    output_layer_node_names = generate_layer_node_names(\"y\", output_layer._width-1, start=1)\n",
    "\n",
    "    def layer_node_decl_template(node_name):\n",
    "        # Generate node declaration string in format of\n",
    "        # sym1 [label=<sym<sub>1</sub>>];\n",
    "        node_sym = node_name[0]\n",
    "        node_idx = node_name[1:]\n",
    "        return f\"{node_sym}{node_idx} [label=<{node_sym}<sub>{node_idx}</sub>>];\"\n",
    "    \n",
    "    def layer_rank_template(node_names):\n",
    "        # Generate concatenation string of\n",
    "        # node names in the same layer\n",
    "        return \"->\".join(node_names) + \";\"\n",
    "    \n",
    "    # Input layer nodes declaration\n",
    "    graph_input_layer_decl = f'''\n",
    "        {{\n",
    "            node [shape=circle, color=chartreuse, style=dotted, fillcolor=chartreuse];\n",
    "            {layer_node_decl_template(input_layer_node_names[0])}\n",
    "        }}\n",
    "        {{\n",
    "            node [shape=circle, color=chartreuse, style=filled, fillcolor=chartreuse];\n",
    "            {NL.join(\n",
    "                list(map(layer_node_decl_template, input_layer_node_names[1:]))\n",
    "            )}\n",
    "        }}\n",
    "        {{\n",
    "            rank=same;\n",
    "            {layer_rank_template(input_layer_node_names)}\n",
    "        }}{NL}'''\n",
    "\n",
    "    # Hidden layer nodes declaration\n",
    "    hidden_layer_rank_template = lambda : \\\n",
    "        NL.join(\n",
    "            [f'''\n",
    "            {{\n",
    "            rank=same;\n",
    "            {layer_rank_template(a_hidden_layer_node_names)}\n",
    "            }}'''\n",
    "            for a_hidden_layer_node_names in hidden_layers_node_names]\n",
    "        )\n",
    "    graph_hidden_layers_decl = f'''{NL.join(f\"\"\"{{\n",
    "        node [shape=circle, color=dodgerblue, style=dotted, fillcolor=dodgerblue];\n",
    "        {layer_node_decl_template(a_hidden_layer_node_names[0])}\n",
    "    }}\n",
    "    {{\n",
    "        node [shape=circle, color=dodgerblue, style=filled, fillcolor=dodgerblue];\n",
    "        {NL.join(\n",
    "            list(map(layer_node_decl_template, a_hidden_layer_node_names))\n",
    "            )}\n",
    "    }}\n",
    "    \"\"\" for a_hidden_layer_node_names in hidden_layers_node_names)}\n",
    "    {hidden_layer_rank_template()}'''\n",
    "    f'''\n",
    "        {{\n",
    "            node [shape=circle, color=dodgerblue, style=filled, fillcolor=dodgerblue];\n",
    "            {NL.join(\n",
    "                [NL.join(\n",
    "                    list(map(layer_node_decl_template, a_hidden_layer_node_names))\n",
    "                )\n",
    "                for a_hidden_layer_node_names in hidden_layers_node_names]\n",
    "            )}\n",
    "        }}\n",
    "        {hidden_layer_rank_template()}'''\n",
    "    \n",
    "    # Output layer nodes declaration\n",
    "    graph_output_layer_decl = f'''\n",
    "        {{\n",
    "            node [shape=circle, color=coral1, style=filled, fillcolor=coral1];\n",
    "        {NL.join(list(map(layer_node_decl_template, output_layer_node_names)))}\n",
    "        }}\n",
    "        {{\n",
    "            rank=same;\n",
    "            {layer_rank_template(output_layer_node_names)}\n",
    "        }}'''\n",
    "\n",
    "    # Layer names labelling\n",
    "    def layer_labelling(type, activation, a_node_name, depth, start=0):\n",
    "        return f'''\n",
    "        l{depth} [shape=plaintext, label=\"Layer {depth+start} ({type} layer){NL}{activation}\"];\n",
    "        l{depth}->{a_node_name};\n",
    "        {{rank=same; l{depth}; {a_node_name}}};\n",
    "        '''\n",
    "    graph_input_layer_labelling = layer_labelling(\"input\", input_layer._type , input_layer_node_names[0], 0)\n",
    "    graph_hidden_layers_labelling = \"\"\n",
    "    for depth, hidden_layer_node_names in enumerate(hidden_layers_node_names):\n",
    "        graph_hidden_layers_labelling += layer_labelling(\"hidden\", hidden_layers[depth]._type, hidden_layer_node_names[0], depth+1)\n",
    "    graph_output_layer_labelling = layer_labelling(\"output\", output_layer._type, output_layer_node_names[0], n_layer-1)\n",
    "\n",
    "    # Weights visualization\n",
    "\n",
    "    graph_weights = \"\"\n",
    "    all_node_names = [input_layer_node_names] + hidden_layers_node_names + [output_layer_node_names]\n",
    "    for i in range(len(all_node_names[:-1])):\n",
    "        line = f\"{{{';'.join(all_node_names[i])}}} -> {{{';'.join(all_node_names[i+1])}}};\\n\"\n",
    "        graph_weights += line\n",
    "    \n",
    "    graph_edges_txt = \"\"\n",
    "    layers_node_names = [input_layer_node_names] + hidden_layers_node_names + [[\"\"] + output_layer_node_names]\n",
    "    for depth in range(n_layer-1):\n",
    "        prev_layer_node_names = layers_node_names[depth]\n",
    "        next_layer_node_names = layers_node_names[depth+1]\n",
    "        weights = neural_network._weights[depth]\n",
    "        for i, prev_node in enumerate(prev_layer_node_names):\n",
    "            for j, next_node in enumerate(next_layer_node_names[1:]):\n",
    "                weight = weights[j][i]\n",
    "                if i == 0:\n",
    "                    graph_edges_txt += f'{prev_node} -> {next_node} [xlabel=\"{weight}\", style=\"dotted\", arrowhead=\"open\"]{NL}'\n",
    "                else:\n",
    "                    graph_edges_txt += f'{prev_node} -> {next_node} [xlabel=\"{weight}\", style=\"filled\", arrowhead=\"open\"]{NL}'\n",
    "\n",
    "    result_txt = \"digraph G {\" \\\n",
    "        + graph_view_format \\\n",
    "        + graph_input_layer_decl \\\n",
    "        + graph_hidden_layers_decl \\\n",
    "        + graph_output_layer_decl \\\n",
    "        + graph_input_layer_labelling \\\n",
    "        + graph_hidden_layers_labelling \\\n",
    "        + graph_output_layer_labelling \\\n",
    "        + \"edge[style=solid, tailport=e, headport=w];\" \\\n",
    "        + graph_edges_txt \\\n",
    "        + \"}\"\n",
    "\n",
    "    return result_txt\n",
    "\n",
    "def build_format(result_txt):\n",
    "    from graphviz import Source\n",
    "    dot = Source(result_txt)\n",
    "    dot.format = 'png'\n",
    "    dot.render('neural_network_01', view=False) \n",
    "    # 'neural_network_01.png'\n",
    "\n",
    "result_txt = generate_txt(neural_network)\n",
    "# print(result_txt)\n",
    "build_format(result_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=2c6d58e5-cc7c-4610-9ec1-8b211eea2409' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "2bdceacd-9048-4177-9a5c-688f4a167d35",
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
